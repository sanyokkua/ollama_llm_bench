- task_id: "coding_java_thread_safe_lru_cache"
  category: "Coding"
  sub_category: "Java"
  question: |
    Implement a thread-safe Least Recently Used (LRU) cache in Java 
    with `get(key)` and `put(key, value)` methods. 
    The cache should:
      - Evict the least recently used entry when capacity is exceeded
      - Handle concurrent access from multiple threads without race conditions
      - Maintain O(1) time complexity for `get` and `put` operations
  expected_answer:
    most_expected: |
      import java.util.LinkedHashMap;
      import java.util.Map;

      public class LRUCache<K, V> {
          private final int capacity;
          private final Map<K, V> cache;

          public LRUCache(int capacity) {
              this.capacity = capacity;
              this.cache = new LinkedHashMap<>(capacity, 0.75f, true) {
                  @Override
                  protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
                      return size() > LRUCache.this.capacity;
                  }
              };
          }

          public synchronized V get(K key) {
              return cache.get(key);
          }

          public synchronized void put(K key, V value) {
              cache.put(key, value);
          }
      }
    good_answer: |
      Uses a `LinkedHashMap` with access order to implement LRU behavior, 
      synchronizes access to avoid race conditions, and ensures eviction 
      when capacity is exceeded.
    pass_option: |
      Any working Java LRU cache implementation with thread safety 
      (e.g., via synchronized methods or locks), even if minor performance 
      optimizations or advanced concurrency utilities are omitted.
  incorrect_direction: |
    Omits thread safety entirely, implements LRU with O(n) operations, 
    or fails to evict entries when capacity is exceeded.
